% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nrdb_api.R
\name{nrdb_events}
\alias{nrdb_events}
\title{Retrieve a contiguous chunk of raw events.}
\usage{
nrdb_events(account_id, api_key, app_id = NULL, attrs = "*", where = NULL,
  start_time = Sys.time() - lubridate::dminutes(60), end_time = Sys.time(),
  limit = 1000, event_type = "Transaction", verbose = F, timeout = 1000,
  sampling_rate = NULL)
}
\arguments{
\item{account_id}{your New Relic account ID}

\item{api_key}{your New Relic NRDB (Insights) API key}

\item{app_id}{the application with the transactions, required unless a where clause is provided}

\item{attrs}{an optional array of attributes to fetch; default is everything (*)}

\item{where}{a clause to use to qualify the events fetched; must specify either app_id or where}

\item{start_time}{the timestamp where to start looking}

\item{end_time}{the end bounds of the timerange}

\item{limit}{the number of events to retrieve}

\item{event_type}{the given transaction type; default is 'Transaction'}

\item{verbose}{for detailed logging}

\item{timeout}{value in ms to wait for a response}

\item{sampling_rate}{the rate of events to use, if sampling.  Value between 0 and 1}
}
\value{
a dataframe with limit rows and the union of all attributes in all sampled events.
}
\description{
This returns a set of events making a best effort to get a contguous chunk.
So if you give a limit of 5000 events it will make successive queries staying
under the limit of 1000 until it has all 5000 events.  You are guaranteed no duplicates
but not guaranteed you won't miss some events if they are sparse or bursty.
}
\details{
There are a lot of transient errors in the NRDB api.  If an error occurs getting a chunk, it will retry 3 times and then give up.
}
